{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bias': DeviceArray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "              0., 0.], dtype=float32),\n",
       " 'kernel': DeviceArray([[ 0.20814848, -1.0710016 ,  0.6439947 , -0.5429579 ,\n",
       "               -0.3246118 ,  1.208985  , -0.257471  , -0.32065013,\n",
       "                0.72582203,  0.08994231,  0.3341397 , -0.22079287,\n",
       "                0.69877183,  0.8303373 ,  0.3428869 ,  0.94781363,\n",
       "                0.08524317, -0.45154864,  0.17062634,  0.8318948 ,\n",
       "               -0.6483707 , -0.24204564, -0.04201688, -0.3538871 ,\n",
       "               -0.22361928, -0.07344878, -0.20832072,  0.17268421,\n",
       "               -0.64753693,  0.59740335, -0.07335723, -0.76099616],\n",
       "              [-0.4295275 ,  1.2338059 ,  0.102417  , -0.13127546,\n",
       "               -0.37081522,  0.18604888,  0.19740908, -0.3535717 ,\n",
       "                0.7684898 ,  0.21345675,  0.5770429 , -0.328339  ,\n",
       "                0.04007532,  0.15846986, -0.9928673 ,  0.2212549 ,\n",
       "               -0.3701994 , -0.6424554 , -0.3648998 ,  0.12597178,\n",
       "               -0.02469591, -0.27812898, -0.22645561, -0.09129761,\n",
       "                0.7858967 ,  1.0210173 , -0.27159536, -0.64969337,\n",
       "                0.10275015, -0.40656534, -0.5714007 , -0.10323345],\n",
       "              [-0.33381036,  0.8070612 ,  0.21314   ,  0.499298  ,\n",
       "               -0.2794949 ,  0.5282369 ,  0.16104864, -0.26513886,\n",
       "               -0.19287321, -0.19362137,  0.13071   , -0.40732282,\n",
       "                0.9995863 ,  0.54519784,  0.12906857,  1.0335478 ,\n",
       "               -0.4564211 , -0.49224326, -0.30296874,  0.37264237,\n",
       "               -0.15083975, -0.8947372 ,  0.22655495, -0.61037207,\n",
       "               -0.06121872,  0.7279354 ,  0.66585314, -0.8731882 ,\n",
       "                0.27885145,  0.5800933 , -0.04471758,  0.32257393]],            dtype=float32)}"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jax.nn import initializers\n",
    "\n",
    "import jax\n",
    "from flax import nn\n",
    "import jax.numpy as jnp\n",
    "from jax import jit\n",
    "\n",
    "from collections.abc import Callable\n",
    "from typing import Any, List\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import dataclasses\n",
    "from dataclasses import dataclass\n",
    "from dataclasses import field\n",
    "\n",
    "from jax import tree_util\n",
    "\n",
    "# TODO: Freeze parameters\n",
    "\n",
    "@jax.tree_util.register_pytree_node_class\n",
    "@dataclass\n",
    "class Module:\n",
    "  # TODO: Add 'kind' to support module lists\n",
    "  def subparam(self, key, default_fn):\n",
    "    if not hasattr(self, 'params'):\n",
    "      self.params = {}\n",
    "    if key not in self.params:\n",
    "      self.params[key] = default_fn()\n",
    "    return self.params[key]\n",
    "\n",
    "  def param(self, key, shape, init_fn):\n",
    "    # TODO: Check if prng_key exists. If not, error should say that you\n",
    "    # can get a prng_key by making this a child of another module\n",
    "    \n",
    "    # TODO: split prng_key with name\n",
    "    return self.subparam(key, lambda: init_fn(self.prng_key, shape))\n",
    "\n",
    "  def child(self, key, module):\n",
    "    return self.subparam(key, lambda: module)\n",
    "  \n",
    "  def is_initialized():\n",
    "    return hasattr(self, 'params')\n",
    "\n",
    "  def module_list(self, key='list'):\n",
    "    return ModuleList(self.subparam(key, lambda: []))\n",
    "\n",
    "  def tree_flatten(self):\n",
    "    meta_dict = dataclasses.asdict(self)\n",
    "    # Needed because we must return a tuple. Each element\n",
    "    # in the tuple need only be a JAXable type\n",
    "    meta = (meta_dict, )\n",
    "\n",
    "    data_dict = {}\n",
    "    for key in dir(self):\n",
    "      val = getattr(self, key)\n",
    "      # TODO: Don't duplicate params and ModuleLists (store ModuleLists somewhere else)\n",
    "      # TODO(!!!): yeah this sucks, we really need to override setattr\n",
    "      if key == 'params' or key == 'counter' or key == 'mlp':\n",
    "        data_dict[key] = val\n",
    "      elif isinstance(val, ModuleList):\n",
    "        data_dict[key] = val.children\n",
    "    # Needed because we must return a tuple. Each element\n",
    "    # in the tuple need only be a JAXable type\n",
    "    data = (data_dict, )\n",
    "\n",
    "    return data, meta\n",
    "  \n",
    "  @classmethod\n",
    "  def tree_unflatten(cls, meta, data):\n",
    "    (meta_dict, ) = meta\n",
    "    (data_dict, ) = data\n",
    "    instance = cls(**meta_dict)\n",
    "    for key in data_dict:\n",
    "      # TODO: Eliminate this if/else and the equivalent one in `tree_flatten` by making\n",
    "      # ModuleList JAX tree-able\n",
    "      if key == 'params' or key == 'counter' or key == 'mlp':\n",
    "        instance.__setattr__(key, data_dict[key])\n",
    "      else:\n",
    "        instance.__setattr__(key, ModuleList(data_dict[key]))\n",
    "    return instance\n",
    "\n",
    "  def __call__(self, *args, **kwargs):\n",
    "    raise NotImplementedError()\n",
    "\n",
    "  #############\n",
    "\n",
    "@dataclass\n",
    "class ModuleList():\n",
    "  children: List[Module] = field(default_factory=list)\n",
    "  cursor: int = 0\n",
    "\n",
    "  def child(self, module):\n",
    "    # TODO: split prng_key with index\n",
    "    module.prng_key = jax.random.PRNGKey(0)\n",
    "    if self.cursor >= len(self.children):\n",
    "      self.children.append(module)\n",
    "    child = self.children[self.cursor]\n",
    "    self.cursor += 1\n",
    "    return child\n",
    "    \n",
    "\n",
    "@tree_util.register_pytree_node_class\n",
    "@dataclass\n",
    "class Dense(Module):\n",
    "  features: int\n",
    "  bias: bool = True\n",
    "  kernel_init: Callable = initializers.lecun_normal()\n",
    "  bias_init: Callable = initializers.zeros\n",
    "\n",
    "  def __call__(self, x):\n",
    "    kernel = self.param('kernel', (x.shape[-1], self.features), self.kernel_init)\n",
    "    x = jnp.dot(x, kernel)\n",
    "    if self.bias:\n",
    "      # QUESTION: Does += work in JAX?\n",
    "      x = x + self.param('bias', (self.features,), self.bias_init)\n",
    "    return x\n",
    "\n",
    "@tree_util.register_pytree_node_class\n",
    "@dataclass\n",
    "class MLP(Module):\n",
    "  depth: int = 3\n",
    "  width: int = 32\n",
    "  features: int = 10\n",
    "\n",
    "  def __call__(self, x):\n",
    "    self.layers = self.module_list()\n",
    "\n",
    "    for i in range(self.depth):\n",
    "      x = nn.relu(self.layers.child(Dense(self.width))(x))\n",
    "    x = self.layers.child(Dense(self.width))(x)\n",
    "    return x\n",
    "\n",
    "@jit\n",
    "def init():\n",
    "  x = np.ones((3, 3))\n",
    "  mlp = MLP(depth=3, width=32)\n",
    "  mlp(x)\n",
    "  return mlp\n",
    "\n",
    "module = init()\n",
    "dir(module)\n",
    "# TODO: Consider making `module.layers` more of an actual list by extending it?\n",
    "module.layers.children[0].params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0903456 [[-0.04370475 -0.14652367 -0.20754965  0.03639566]]\n",
      "1.0903456 [[ 0.00516562 -0.04317067 -0.07185964  0.04282168]]\n",
      "1.0167608 [[0.05 0.05 0.05 0.05]]\n",
      "0.95 [[0.075 0.075 0.075 0.075]]\n",
      "0.925 [[0.1 0.1 0.1 0.1]]\n",
      "0.9 [[0.125 0.125 0.125 0.125]]\n",
      "0.875 [[0.15 0.15 0.15 0.15]]\n",
      "0.85 [[0.17500001 0.17500001 0.17500001 0.17500001]]\n",
      "0.825 [[0.20000002 0.20000002 0.20000002 0.20000002]]\n",
      "0.79999995 [[0.22500002 0.22500002 0.22500002 0.22500002]]\n",
      "0.775 [[0.25000003 0.25000003 0.25000003 0.25000003]]\n",
      "0.75 [[0.27500004 0.27500004 0.27500004 0.27500004]]\n",
      "0.72499996 [[0.30000004 0.30000004 0.30000004 0.30000004]]\n",
      "0.6999999 [[0.32500005 0.32500005 0.32500005 0.32500005]]\n",
      "0.67499995 [[0.35000005 0.35000005 0.35000005 0.35000005]]\n",
      "0.65 [[0.37500006 0.37500006 0.37500006 0.37500006]]\n",
      "0.62499994 [[0.40000007 0.40000007 0.40000007 0.40000007]]\n",
      "0.5999999 [[0.42500007 0.42500007 0.42500007 0.42500007]]\n",
      "0.5749999 [[0.45000008 0.45000008 0.45000008 0.45000008]]\n",
      "0.54999995 [[0.47500008 0.47500008 0.47500008 0.47500008]]\n",
      "0.5249999 [[0.50000006 0.50000006 0.50000006 0.50000006]]\n",
      "0.49999994 [[0.52500004 0.52500004 0.52500004 0.52500004]]\n",
      "0.47499996 [[0.55 0.55 0.55 0.55]]\n",
      "0.45 [[0.575 0.575 0.575 0.575]]\n",
      "0.425 [[0.59999996 0.59999996 0.59999996 0.59999996]]\n",
      "0.40000004 [[0.62499994 0.62499994 0.62499994 0.62499994]]\n",
      "0.37500006 [[0.6499999 0.6499999 0.6499999 0.6499999]]\n",
      "0.35000008 [[0.6749999 0.6749999 0.6749999 0.6749999]]\n",
      "0.3250001 [[0.69999987 0.69999987 0.69999987 0.69999987]]\n",
      "0.30000013 [[0.72499985 0.72499985 0.72499985 0.72499985]]\n",
      "0.27500015 [[0.7499998 0.7499998 0.7499998 0.7499998]]\n",
      "0.25000018 [[0.7749998 0.7749998 0.7749998 0.7749998]]\n",
      "0.2250002 [[0.7999998 0.7999998 0.7999998 0.7999998]]\n",
      "0.20000023 [[0.82499975 0.82499975 0.82499975 0.82499975]]\n",
      "0.17500025 [[0.8499997 0.8499997 0.8499997 0.8499997]]\n",
      "0.15000027 [[0.8749997 0.8749997 0.8749997 0.8749997]]\n",
      "0.1250003 [[0.8999997 0.8999997 0.8999997 0.8999997]]\n",
      "0.10000032 [[0.92499965 0.92499965 0.92499965 0.92499965]]\n",
      "0.075000346 [[0.94999963 0.94999963 0.94999963 0.94999963]]\n",
      "0.05000037 [[0.9749996 0.9749996 0.9749996 0.9749996]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# NOTE: This is again like Flax's current `Model` -- you take gradients\n",
    "# w.r.t. it.\n",
    "def loss_fn(mlp):\n",
    "  x = np.ones((1, 3))\n",
    "  y_true = np.ones((1, 4))\n",
    "  y_pred = mlp(x)\n",
    "  return jnp.mean(jnp.abs(y_pred - y_true))\n",
    "\n",
    "@jit\n",
    "def opt_step(mlp):\n",
    "  # TODO: Mark `mlp` as dead\n",
    "  loss, grad = jax.value_and_grad(loss_fn)(mlp)\n",
    "  lr = 1e-1\n",
    "  return loss, jax.tree_multimap(lambda w, g: w - lr * g, mlp, grad)\n",
    "\n",
    "mlp = MLP(depth=3, width=4)\n",
    "for i in range(40):\n",
    "  loss, mlp = opt_step(mlp)\n",
    "  print(loss, mlp(np.ones((1, 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter(value=DeviceArray(3, dtype=int32))\n",
      "Counter(value=DeviceArray(6, dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "@jax.tree_util.register_pytree_node_class\n",
    "@dataclass\n",
    "class Counter:\n",
    "  # QUESTION: register_buffer_variable? field(kind='param'|'counter'|'log', ...)\n",
    "  # Need special wrapper that's not Module. More like Jonathan's dataclass. Then\n",
    "  # Have Module use that decorator as well.\n",
    "  value: int = 0\n",
    "\n",
    "  def __call__(self):\n",
    "    self.value = self.value + 1\n",
    "\n",
    "  def tree_flatten(self):\n",
    "    return (self.value, ), None\n",
    "  \n",
    "  @classmethod\n",
    "  def tree_unflatten(cls, meta, data):\n",
    "    value, = data\n",
    "    return cls(value)\n",
    "\n",
    "counter = Counter()\n",
    "@jit\n",
    "def inc3(c):\n",
    "  c()\n",
    "  c()\n",
    "  c()\n",
    "  return c\n",
    "\n",
    "counter = inc3(counter)\n",
    "print(counter)\n",
    "counter = inc3(counter)\n",
    "print(counter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter(value=DeviceArray(3, dtype=int32))\n",
      "Counter(value=DeviceArray(6, dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "@tree_util.register_pytree_node_class\n",
    "class WithCounter(Module):\n",
    "  def __call__(self):\n",
    "    # QUESTION: Use __setattr__ so that this becomes\n",
    "    #     self.counter = Counter()?\n",
    "    self.counter = self.child(\"counter\", Counter())\n",
    "    pass\n",
    "\n",
    "# TODO: @cloned -- simulate jit but still being able to debug\n",
    "  \n",
    "@jit\n",
    "def inc3_with(with_counter):\n",
    "  with_counter.counter()\n",
    "  with_counter.counter()\n",
    "  with_counter.counter()\n",
    "  return with_counter\n",
    "\n",
    "with_counter = WithCounter()\n",
    "with_counter()\n",
    "# TODO: Somehow make this code fail -- it doesn't behave\n",
    "# the same under a jit\n",
    "# print(increment_twice(with_counter).counter)\n",
    "# print(increment_twice(with_counter).counter)\n",
    "\n",
    "with_counter = inc3_with(with_counter)\n",
    "print(with_counter.counter)\n",
    "with_counter = inc3_with(with_counter)\n",
    "print(with_counter.counter)\n",
    "\n",
    "# TODO: If we use __setattr__ then can we not place those things on `self.params`? Then\n",
    "# this won't be possible to try.\n",
    "# with_counter = inc3_with(with_counter)\n",
    "# print(with_counter.params['counter'])\n",
    "# with_counter = inc3_with(with_counter)\n",
    "# print(with_counter.params['counter'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(depth=3, width=4, features=10)\n",
      "1.0903456 Counter(value=1) [[ 0.00516562 -0.04317067 -0.07185964  0.04282168]]\n",
      "1.0167607 Counter(value=2) [[0.05 0.05 0.05 0.05]]\n",
      "0.95 Counter(value=3) [[0.075 0.075 0.075 0.075]]\n",
      "0.925 Counter(value=4) [[0.1 0.1 0.1 0.1]]\n",
      "0.9 Counter(value=5) [[0.125 0.125 0.125 0.125]]\n",
      "0.875 Counter(value=6) [[0.15 0.15 0.15 0.15]]\n",
      "0.85 Counter(value=7) [[0.17500001 0.17500001 0.17500001 0.17500001]]\n",
      "0.825 Counter(value=8) [[0.20000002 0.20000002 0.20000002 0.20000002]]\n",
      "0.79999995 Counter(value=9) [[0.22500002 0.22500002 0.22500002 0.22500002]]\n",
      "0.775 Counter(value=10) [[0.25000003 0.25000003 0.25000003 0.25000003]]\n",
      "0.75 Counter(value=11) [[0.27500004 0.27500004 0.27500004 0.27500004]]\n",
      "0.72499996 Counter(value=12) [[0.30000004 0.30000004 0.30000004 0.30000004]]\n",
      "0.6999999 Counter(value=13) [[0.32500005 0.32500005 0.32500005 0.32500005]]\n",
      "0.67499995 Counter(value=14) [[0.35000005 0.35000005 0.35000005 0.35000005]]\n",
      "0.65 Counter(value=15) [[0.37500006 0.37500006 0.37500006 0.37500006]]\n",
      "0.62499994 Counter(value=16) [[0.40000007 0.40000007 0.40000007 0.40000007]]\n",
      "0.5999999 Counter(value=17) [[0.42500007 0.42500007 0.42500007 0.42500007]]\n",
      "0.5749999 Counter(value=18) [[0.45000008 0.45000008 0.45000008 0.45000008]]\n",
      "0.54999995 Counter(value=19) [[0.47500008 0.47500008 0.47500008 0.47500008]]\n",
      "0.5249999 Counter(value=20) [[0.50000006 0.50000006 0.50000006 0.50000006]]\n",
      "0.49999994 Counter(value=21) [[0.52500004 0.52500004 0.52500004 0.52500004]]\n",
      "0.47499996 Counter(value=22) [[0.55 0.55 0.55 0.55]]\n",
      "0.45 Counter(value=23) [[0.575 0.575 0.575 0.575]]\n",
      "0.425 Counter(value=24) [[0.59999996 0.59999996 0.59999996 0.59999996]]\n",
      "0.40000004 Counter(value=25) [[0.62499994 0.62499994 0.62499994 0.62499994]]\n",
      "0.37500006 Counter(value=26) [[0.6499999 0.6499999 0.6499999 0.6499999]]\n",
      "0.35000008 Counter(value=27) [[0.6749999 0.6749999 0.6749999 0.6749999]]\n",
      "0.3250001 Counter(value=28) [[0.69999987 0.69999987 0.69999987 0.69999987]]\n",
      "0.30000013 Counter(value=29) [[0.72499985 0.72499985 0.72499985 0.72499985]]\n",
      "0.27500015 Counter(value=30) [[0.7499998 0.7499998 0.7499998 0.7499998]]\n",
      "0.25000018 Counter(value=31) [[0.7749998 0.7749998 0.7749998 0.7749998]]\n",
      "0.2250002 Counter(value=32) [[0.7999998 0.7999998 0.7999998 0.7999998]]\n",
      "0.20000023 Counter(value=33) [[0.82499975 0.82499975 0.82499975 0.82499975]]\n",
      "0.17500025 Counter(value=34) [[0.8499997 0.8499997 0.8499997 0.8499997]]\n",
      "0.15000027 Counter(value=35) [[0.8749997 0.8749997 0.8749997 0.8749997]]\n",
      "0.1250003 Counter(value=36) [[0.8999997 0.8999997 0.8999997 0.8999997]]\n",
      "0.10000032 Counter(value=37) [[0.92499965 0.92499965 0.92499965 0.92499965]]\n",
      "0.075000346 Counter(value=38) [[0.94999963 0.94999963 0.94999963 0.94999963]]\n",
      "0.05000037 Counter(value=39) [[0.9749996 0.9749996 0.9749996 0.9749996]]\n",
      "0.025000393 Counter(value=40) [[0.9999996 0.9999996 0.9999996 0.9999996]]\n"
     ]
    }
   ],
   "source": [
    "@tree_util.register_pytree_node_class\n",
    "class MLPAndCounter(Module):\n",
    "  def __init__(self):\n",
    "    self.mlp = self.child('mlp', MLP(depth=3, width=4))\n",
    "    self.counter = self.child('counter', Counter())\n",
    "\n",
    "def clone(x):\n",
    "  return jax.tree_map(lambda v: v, x)\n",
    "    \n",
    "# TODO: Is there a general pattern for extracting just the \n",
    "# trainable parameters? Use `kind`\n",
    "def opt_step(mlp_and_counter):\n",
    "  mlp_and_counter = clone(mlp_and_counter)\n",
    "  mlp_and_counter.counter()\n",
    "  loss, grad = jax.value_and_grad(loss_fn)(mlp_and_counter.mlp)\n",
    "  lr = 1e-1\n",
    "  # TODO: This really implies we should probably override __setattr__\n",
    "  # TODO(!!!): Why did I need to do this? Mental model breakdown!\n",
    "  old_mlp = mlp_and_counter.mlp\n",
    "  del mlp_and_counter.params['mlp']\n",
    "  del mlp_and_counter.mlp\n",
    "  mlp_and_counter.mlp = mlp_and_counter.child('mlp', jax.tree_multimap(lambda w, g: w - lr * g, old_mlp, grad))\n",
    "  return loss, mlp_and_counter\n",
    "\n",
    "@jit\n",
    "def init(): \n",
    "  mlp_and_counter = MLPAndCounter()\n",
    "  mlp_and_counter.mlp(np.ones((1, 3)))\n",
    "  print(mlp_and_counter.mlp)\n",
    "  return mlp_and_counter\n",
    "\n",
    "mlp_and_counter = init()\n",
    "\n",
    "for i in range(40):\n",
    "  loss, mlp_and_counter = opt_step(mlp_and_counter)\n",
    "  print(loss, mlp_and_counter.counter, mlp_and_counter.mlp(np.ones((1, 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(depth=3, width=4, features=10)\n",
      "1.0903456 2 [[ 0.00516562 -0.04317067 -0.07185964  0.04282168]]\n",
      "1.0167607 3 [[0.05 0.05 0.05 0.05]]\n",
      "0.95 4 [[0.075 0.075 0.075 0.075]]\n",
      "0.925 5 [[0.1 0.1 0.1 0.1]]\n",
      "0.9 6 [[0.125 0.125 0.125 0.125]]\n",
      "0.875 7 [[0.15 0.15 0.15 0.15]]\n",
      "0.85 8 [[0.17500001 0.17500001 0.17500001 0.17500001]]\n",
      "0.825 9 [[0.20000002 0.20000002 0.20000002 0.20000002]]\n",
      "0.79999995 10 [[0.22500002 0.22500002 0.22500002 0.22500002]]\n",
      "0.775 11 [[0.25000003 0.25000003 0.25000003 0.25000003]]\n",
      "0.75 12 [[0.27500004 0.27500004 0.27500004 0.27500004]]\n",
      "0.72499996 13 [[0.30000004 0.30000004 0.30000004 0.30000004]]\n",
      "0.6999999 14 [[0.32500005 0.32500005 0.32500005 0.32500005]]\n",
      "0.67499995 15 [[0.35000005 0.35000005 0.35000005 0.35000005]]\n",
      "0.65 16 [[0.37500006 0.37500006 0.37500006 0.37500006]]\n",
      "0.62499994 17 [[0.40000007 0.40000007 0.40000007 0.40000007]]\n",
      "0.5999999 18 [[0.42500007 0.42500007 0.42500007 0.42500007]]\n",
      "0.5749999 19 [[0.45000008 0.45000008 0.45000008 0.45000008]]\n",
      "0.54999995 20 [[0.47500008 0.47500008 0.47500008 0.47500008]]\n",
      "0.5249999 21 [[0.50000006 0.50000006 0.50000006 0.50000006]]\n",
      "0.49999994 22 [[0.52500004 0.52500004 0.52500004 0.52500004]]\n",
      "0.47499996 23 [[0.55 0.55 0.55 0.55]]\n",
      "0.45 24 [[0.575 0.575 0.575 0.575]]\n",
      "0.425 25 [[0.59999996 0.59999996 0.59999996 0.59999996]]\n",
      "0.40000004 26 [[0.62499994 0.62499994 0.62499994 0.62499994]]\n",
      "0.37500006 27 [[0.6499999 0.6499999 0.6499999 0.6499999]]\n",
      "0.35000008 28 [[0.6749999 0.6749999 0.6749999 0.6749999]]\n",
      "0.3250001 29 [[0.69999987 0.69999987 0.69999987 0.69999987]]\n",
      "0.30000013 30 [[0.72499985 0.72499985 0.72499985 0.72499985]]\n",
      "0.27500015 31 [[0.7499998 0.7499998 0.7499998 0.7499998]]\n",
      "0.25000018 32 [[0.7749998 0.7749998 0.7749998 0.7749998]]\n",
      "0.2250002 33 [[0.7999998 0.7999998 0.7999998 0.7999998]]\n",
      "0.20000023 34 [[0.82499975 0.82499975 0.82499975 0.82499975]]\n",
      "0.17500025 35 [[0.8499997 0.8499997 0.8499997 0.8499997]]\n",
      "0.15000027 36 [[0.8749997 0.8749997 0.8749997 0.8749997]]\n",
      "0.1250003 37 [[0.8999997 0.8999997 0.8999997 0.8999997]]\n",
      "0.10000032 38 [[0.92499965 0.92499965 0.92499965 0.92499965]]\n",
      "0.075000346 39 [[0.94999963 0.94999963 0.94999963 0.94999963]]\n",
      "0.05000037 40 [[0.9749996 0.9749996 0.9749996 0.9749996]]\n",
      "0.025000393 41 [[0.9999996 0.9999996 0.9999996 0.9999996]]\n"
     ]
    }
   ],
   "source": [
    "@tree_util.register_pytree_node_class\n",
    "class MLPAndCounter2(Module):\n",
    "  def __call__(self, x):\n",
    "    self.counter = self.child('counter', Counter())\n",
    "    self.counter()\n",
    "    self.mlp = self.child('mlp', MLP(depth=3, width=4))\n",
    "    return self.mlp(x)\n",
    "  \n",
    "def init2(): \n",
    "  mlp_and_counter = MLPAndCounter2()\n",
    "  mlp_and_counter(np.ones((1, 3)))\n",
    "  print(mlp_and_counter.mlp)\n",
    "  return mlp_and_counter\n",
    "\n",
    "mlp_and_counter2 = init2()\n",
    "\n",
    "for i in range(40):\n",
    "  loss, mlp_and_counter2 = opt_step(mlp_and_counter2)\n",
    "  print(loss, mlp_and_counter2.counter.value, mlp_and_counter2.mlp(np.ones((1, 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter(value=2)\n",
      "Counter(value=4)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AutoEncoder(Module):\n",
    "  width: int = 32\n",
    "  depth: int = 3\n",
    "\n",
    "  def encode(x):\n",
    "    self.input_shape = x.shape\n",
    "    self.encoder_layers = self.module_list('encoder')\n",
    "\n",
    "    z = x\n",
    "    for i in range(self.depth):\n",
    "      z = self.encoder_layers.child(Dense(self.width))(x)\n",
    "      z = nn.relu(z)\n",
    "    # final layer without relu\n",
    "    z = self.decoder_layers.child(Dense(self.width))(x)\n",
    "    return z\n",
    "      \n",
    "  def decode(z):\n",
    "    assert hasattr(self, 'input_shape'), \"Need to call `encode` to know the input shape\"\n",
    "    self.decoder_layers = self.module_list('decoder')\n",
    "\n",
    "    x = z\n",
    "    for i in range(self.depth):\n",
    "      x = self.decoder_layers.child(Dense(self.width))(x)\n",
    "      x = nn.relu(x)\n",
    "\n",
    "    x = self.decoder_layers.child(Dense(np.prod(self.input_shape)))(x)\n",
    "    x = x.reshape(self.input_shape)\n",
    "    return x\n",
    "\n",
    "  def __call__(x)\n",
    "    return self.decode(self.encode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger(Module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
